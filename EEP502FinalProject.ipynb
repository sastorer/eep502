{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d67480b-5f25-42b9-9507-a7024ea2ff46",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "## Hallucinating the Constitution\n",
    "\n",
    "Consider the constitution of the United States:\n",
    "> https://www.usconstitution.net/const.txt .\n",
    "\n",
    "This document contains upper- and lower-case letters, numbers, and basic punctuation. \n",
    "\n",
    "**One letter prediction:**\n",
    "1. Find the set of all characters used in the document. Call the number of characters $n$. \n",
    "2. Create an $n \\times n$ matrix whose $i,j$ entry is the probability that the next character is $j$ given that the current character is $i$. Estimate this probability by looking at all occurrences of character $i$ in the document and the number of times character $j$ immediately follows it. \n",
    "3. Simulate this system as a Markov chain that starts with an arbitrary capital letter and continues until it gets to a space. Produce $100$ random \"words\" this way. How many of them are actual words? Use a [Scrabble dictionary](https://scrabble.hasbro.com/en-us/tools#dictionary) if you are not certain whether a given sequence is a word. \n",
    "\n",
    "**Two letter prediction:**\n",
    "1. Create an $n \\times n \\times n$ tensor whose $i,j,k$ entry is the probability that the next character is $k$ given that the current character is $j$ and the previous character is $i$. Use the document to empirically find these probabilities. \n",
    "2. Use this model to construct random words. \n",
    "\n",
    "**Sentence prediction:**\n",
    "\n",
    "Do a one word prediction, but use all the unique *words* in the document. Hallucinate sentences. Consider a punctuation mark as a word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cd797-367f-460d-89e0-1076122caa58",
   "metadata": {},
   "source": [
    "# Mathematical Explanation\n",
    "\n",
    "Markov chains are memoryless and highly rely on a transition matrix full of probabilities. So, if $X$ is the prediction, $X_{t+1}\\text{ depends only on }X_t$\n",
    "\n",
    "The Markov Property can be defined as:\n",
    "\n",
    "$\\mathbb{P}(X_{t+1} = s | X_t = s_t, X_{t−1} = s_{t−1}, \\dots , X_0 = s_0) = \\mathbb{P}(X_{t+1} = s | X_t = s_t)$ for all $t = 1, 2, 3, \\dots$ and for all states $s_0, s_1, . . . , s_t, s$.\n",
    "\n",
    "The transition matrix is filled using:\n",
    "\n",
    "$p_{ij} = \\mathbb{P}(X_{t+1} = j | X_t = i)$ for $i, j \\in S$, $t = 0, 1, 2, \\dots$\n",
    "\n",
    "The rows of the transition matrix always sum to 1. Simply, $X_{t+1}$ must take one of the listed values. The transition matrix is always a square matrix ($N \\times N$), because $X_{t+1}$ and $X_t$ both take values in the same state space $S$ (of size $N$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f88c95-edd3-445d-a9d9-48a9b25b8ffc",
   "metadata": {},
   "source": [
    "# Code Setup\n",
    "\n",
    "The following code includes import needed as well as the helper functions necessary to make the code run. Each section is commented appropriately to explain what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a7bce-f085-477f-a3d1-75ef57f82183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "\n",
    "def transition_matrix(transitions):\n",
    "    df = pd.DataFrame(transitions)\n",
    "    # Create a new column with data shifted one space\n",
    "    df['shift'] = df[0].shift(-1)\n",
    "    # Add a count column (for group by function)\n",
    "    df['count'] = 1\n",
    "    # Groupby and then unstack, fill the zeros\n",
    "    trans_mat = df.groupby([0, 'shift']).count().unstack().fillna(0)\n",
    "    # Normalise by occurences and save values to get transition matrix\n",
    "    trans_mat = trans_mat.div(trans_mat.sum(axis=1), axis=0).values\n",
    "    return trans_mat\n",
    "\n",
    "def transition_matrix_3d(transitions):\n",
    "    df = pd.DataFrame(transitions)\n",
    "    # Create a new column with data shifted one space\n",
    "    df['shift'] = df[0].shift(-1)\n",
    "    # Add a count column (for group by function)\n",
    "    df['count'] = 1\n",
    "    # Create a new column with data shifted two spaces\n",
    "    df['shift2'] = df[0].shift(-2)\n",
    "    # Groupby and then unstack, fill the zeros\n",
    "    trans_mat3d = df.groupby([0, 'shift', 'shift2']).count().unstack().fillna(0)\n",
    "    # Normalise by occurences and save values to get transition matrix\n",
    "    trans_mat3d = trans_mat3d.div(trans_mat3d.sum(axis=1), axis=0)\n",
    "    return trans_mat3d\n",
    "\n",
    "def make_pairs(data):\n",
    "    for i in range(len(data)-1):\n",
    "        yield (data[i], data[i+1])\n",
    "        \n",
    "# Helper function to find the letter after a given pair of letters throught the given corpus\n",
    "def get_next_letter(word, corpus):\n",
    "    index = 0\n",
    "    dataAfter = []\n",
    "    while index < len(corpus):\n",
    "        index = corpus.find(word, index)\n",
    "        if index == -1:\n",
    "            break\n",
    "        if index < len(corpus)-2:\n",
    "            dataAfter.append(corpus[index+2])\n",
    "        index += len(word)\n",
    "    return dataAfter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ff855-19c7-4253-9a1b-c5f61c420b2f",
   "metadata": {},
   "source": [
    "The following code does necessary setup to format the data as well as create word and letter dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec113435-213d-42c0-afb8-4faf881de8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file and read in the text\n",
    "strPath = \"constitution.txt\"\n",
    "f = open(strPath)\n",
    "strText = f.read()\n",
    "# Put a space before any punctuation\n",
    "strText = re.sub('([.,!?():;])', r' \\1 ', strText)\n",
    "# Remove double spaces\n",
    "strText = re.sub('\\s{2,}', ' ', strText)\n",
    "# Split the long string into a list of words\n",
    "listText = strText.split()\n",
    "# Take the original long string and separate it into a list of letters\n",
    "letterText = []\n",
    "for letter in strText:\n",
    "    if letter != '\\n':\n",
    "        letterText.append(letter)\n",
    "        \n",
    "###### Setup for generating words ######       \n",
    "# Create the transition probability matrix for the constitiution words\n",
    "wordTransition = transition_matrix(listText)\n",
    "# Create a list of unique words \n",
    "uniqueText = np.unique(listText)\n",
    "# Create word pairs to enable key/value sorting in the next step\n",
    "pairsWords = make_pairs(listText)\n",
    "# Take the word pairs and sort them into a dictionary where the key \n",
    "# is one word and the values are all possible words that can follow\n",
    "wordDict = {}\n",
    "for word_1, word_2 in pairsWords:\n",
    "    if word_1 in wordDict.keys():\n",
    "        wordDict[word_1].append(word_2)\n",
    "    else:\n",
    "        wordDict[word_1] = [word_2]\n",
    "\n",
    "###### Setup for generating letters based on one letter ######\n",
    "# create the transition probability matrix\n",
    "letterTransition = transition_matrix(letterText)\n",
    "# create a list of unique words\n",
    "# (again conveniently the dame order that the transition matrix is in)\n",
    "uniqueLetters = np.unique(letterText)\n",
    "# Create letter pairs to enable key/value sorting in the next step\n",
    "pairsLetters = make_pairs(letterText)\n",
    "# Take the letter pairs and sort them into a dictionary where the key\n",
    "# is one letter and the values are all possible letters that can follow\n",
    "letterDict = {}\n",
    "for letter_1, letter_2 in pairsLetters:\n",
    "    if letter_1 in letterDict.keys():\n",
    "        letterDict[letter_1].append(letter_2)\n",
    "    else:\n",
    "        letterDict[letter_1] = [letter_2]\n",
    "\n",
    "###### Setup for generating letters based on two letters ######\n",
    "# Create the transition probability matrix\n",
    "doubleLetterTransition = transition_matrix_3d(letterText)\n",
    "# Create letter pairs and then check the corpus to see if they actually exist\n",
    "letterPairs = []\n",
    "actualPairs = []\n",
    "for x in uniqueLetters:\n",
    "    for y in uniqueLetters:\n",
    "        letterPairs.append(x+y)\n",
    "for pair in letterPairs:\n",
    "    if strText.count(pair) > 0:\n",
    "        actualPairs.append(pair)\n",
    "# Take the letter pairs and sort them into a dictionary where the key\n",
    "# is two letters and the values are all possible letters that can follow the pair\n",
    "pairsDict = {}\n",
    "for pair in actualPairs:\n",
    "    if pair in pairsDict.keys():\n",
    "        for letter in get_next_letter(pair, ''.join(letterText)):\n",
    "            pairsDict[pair].append(letter)\n",
    "    else:\n",
    "        pairsDict[pair] = []\n",
    "        for letter in get_next_letter(pair, ''.join(letterText)):\n",
    "            pairsDict[pair].append(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4c54f-d75a-4f8f-95b3-730d539f3c88",
   "metadata": {},
   "source": [
    "The following code defines a function to generate letters based on a single letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792746e-1d18-49d1-81f5-b2fd1ee05551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constitution_letters(n):\n",
    "    letterList = []\n",
    "    first_letter = \"w\"\n",
    "    #Ensure the first letter isn't a symbol and starts with a capital letter\n",
    "    while first_letter.islower() or first_letter in ['!', ',', '.', '?', ':', ';', '-', '(', ')', ' ']:\n",
    "            first_letter = np.random.choice(letterText)\n",
    "    letterList.append(first_letter)\n",
    "\n",
    "    count = n\n",
    "    while count != 0:\n",
    "        # Build a list of probabilities to feed to np.random.choice \n",
    "        # (it needs to be the same length as the letters to choose from)\n",
    "        probabilities = []\n",
    "        # Get the unique letters that can follow the last letter in letter list \n",
    "        # (want to make sure all of the probabilities add up to 1)\n",
    "        uniqueLetterDict = np.unique(letterDict[letterList[-1]])\n",
    "        # For each entry in that unique list of letters, append the corresponding probability \n",
    "        # from the transition matrix to the list of probabilities\n",
    "        for entry in uniqueLetterDict:\n",
    "            probabilities.append(letterTransition[np.where(uniqueLetters == letterList[-1])[0][0]][np.where(uniqueLetters == entry)[0][0]])\n",
    "        # Finally, choose a word given all of the parameters!\n",
    "        letterList.append(np.random.choice(uniqueLetterDict, p=probabilities))\n",
    "        # If that choice is a space, consider the preceeding choices a word and deduct from the word count\n",
    "        if letterList[-1] == ' ':\n",
    "            count = count - 1\n",
    "\n",
    "    # Print and return the final list of generated letters in string form with nothing between them\n",
    "    print(''.join(letterList))\n",
    "    return ''.join(letterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6defda2-c6c7-48b9-9a89-a0ad7a821c3d",
   "metadata": {},
   "source": [
    "The following code defines a function to generate letters based on the two preceeding letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8e92e-600c-411c-adf8-a07b9e2d05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constitution_letters_double(n):\n",
    "    # Start with a pair of letters that we know is in the corpus\n",
    "    letterList = ['W','e']\n",
    "    count = n\n",
    "    while count != 0:\n",
    "        # Build a list of probabilities to feed to np.random.choice \n",
    "        # (it needs to be the same length as the letters to choose from)\n",
    "        probabilities = []\n",
    "        # Get the unique letters that can follow the last pair of letters in letter list \n",
    "        # (want to make sure all of the probabilities add up to 1)\n",
    "        pair = letterList[-2]+letterList[-1]\n",
    "        if pair in pairsDict.keys():\n",
    "            uniqueLetterDict = np.unique(pairsDict[pair])\n",
    "            # For each entry in that unique list of letters, append the corresponding probability \n",
    "            # from the transition matrix to the list of probabilities\n",
    "            for entry in uniqueLetterDict:\n",
    "                if np.where(uniqueLetters == entry)[0].size != 0:\n",
    "                    probabilities.append(doubleLetterTransition.loc[(letterList[-2], letterList[-1])][(np.where(uniqueLetters == entry)[0][0])])\n",
    "            # Finally, choose a word given all of the parameters!\n",
    "            letterList.append(np.random.choice(uniqueLetterDict, p=probabilities))\n",
    "            # If that choice is a space, consider the preceeding choices a word and deduct from the word count\n",
    "            if letterList[-1] == ' ':\n",
    "                count = count - 1\n",
    "        else:\n",
    "            # If we made a bad choice and that pair isn't in our dictionary, remove the last guess and try again\n",
    "            letterList = letterList[:-2]\n",
    "\n",
    "    # Print and return the final list of generated letters in string form with nothing between them\n",
    "    print(''.join(letterList))\n",
    "    return ''.join(letterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5016930-a910-4a5a-a2ea-25ba1106fe50",
   "metadata": {},
   "source": [
    "The following code defines a function to generate words based on the previous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9607be-9ebd-4399-bbe2-1c5fea48923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consitution_words(n):\n",
    "    wordList = []\n",
    "    first_word = \"word\"\n",
    "    #Ensure the first word isn't a symbol and starts with a capital letter\n",
    "    while first_word.islower() or first_word in ['!', ',', '.', '?', ':', ';', '-', '(', ')', ' ']:\n",
    "        first_word = np.random.choice(listText)\n",
    "    wordList.append(first_word)\n",
    "\n",
    "    for i in range(n):\n",
    "        # Build a list of probabilities to feed to np.random.choice \n",
    "        # (it needs to be the same length as the words to choose from)\n",
    "        probabilities = []\n",
    "        # Get the unique words that can follow the last word in word list \n",
    "        # (want to make sure all of the probabilities add up to 1)\n",
    "        uniqueDict = np.unique(wordDict[wordList[-1]])\n",
    "        # For each entry in that unique list of words, append the corresponding probability \n",
    "        # from the transition matrix to the list of probabilities\n",
    "        for entry in uniqueDict:\n",
    "            probabilities.append(wordTransition[np.where(uniqueText == wordList[-1])[0][0]][np.where(uniqueText == entry)[0][0]])\n",
    "        # Finally, choose a word given all of the parameters!\n",
    "        wordList.append(np.random.choice(uniqueDict, p=probabilities))\n",
    "\n",
    "    # Print and return the final list of generated words in string form with a space between them\n",
    "    print(' '.join(wordList) + '.')\n",
    "    return ' '.join(wordList) + '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d91341-6857-4dbd-b267-f2f2aa742404",
   "metadata": {},
   "source": [
    "Finally, lets output some values using all of the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85963693-3ae0-47d4-a7da-fdc8d3bec5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "letterstr = generate_constitution_letters(100)\n",
    "\n",
    "# Check how many words are in the generated string of letters\n",
    "setofwords = set(words.words())\n",
    "wordCount = 0\n",
    "for word in letterstr.split():    \n",
    "    if word in setofwords:\n",
    "        if len(word) != 1:\n",
    "            wordCount = wordCount + 1\n",
    "print(\"There are {} words here.\".format(wordCount))\n",
    "print('\\n')\n",
    "\n",
    "doubleletterstr = generate_constitution_letters_double(100)\n",
    "\n",
    "# Check how many words are in the generated string of letters\n",
    "wordCountDouble = 0\n",
    "for word in doubleletterstr.split():    \n",
    "    if word in setofwords:\n",
    "        if len(word) != 1:\n",
    "            wordCountDouble = wordCountDouble + 1\n",
    "print(\"There are {} words here.\".format(wordCountDouble))\n",
    "print('\\n')\n",
    "generate_consitution_words(500);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
